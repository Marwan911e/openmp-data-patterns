# OpenMP Programming Assignment - Sheet #03

## Data Decomposition with OpenMP

This repository contains implementations of 6 parallel programming tasks using OpenMP, demonstrating various data decomposition patterns and parallel data processing techniques.

---

## üìã Assignment Overview

**Course:** CCS4210 - High Performance Computing  
**Instructor:** Dr. Hanan Hassan  
**TA:** Marwa Alazab  
**Topic:** Data Decomposition Strategies

### Tasks Implemented:

1. **Large Matrix Multiplication** - Block decomposition for matrix operations
2. **Parallel File Encryption** - Chunk-based data decomposition
3. **Parallel Histogram Computation** - Data partitioning with synchronization
4. **Matrix Transpose** - Block data partition strategy
5. **Vector Addition** - Element-wise data partitioning
6. **Sparse Matrix-Vector Multiplication** - CSR format with row decomposition

---

## üìÅ Project Structure

```
assignment-three/
‚îú‚îÄ‚îÄ Task1-Matrix-Multiplication/
‚îÇ   ‚îú‚îÄ‚îÄ matrix_multiplication.c        # Block decomposition implementation
‚îÇ   ‚îî‚îÄ‚îÄ README.md                       # Task documentation
‚îÇ
‚îú‚îÄ‚îÄ Task2-File-Encryption/
‚îÇ   ‚îú‚îÄ‚îÄ file_encryption.c              # Chunk-based parallel encryption
‚îÇ   ‚îî‚îÄ‚îÄ README.md                       # Task documentation
‚îÇ
‚îú‚îÄ‚îÄ Task3-Histogram/
‚îÇ   ‚îú‚îÄ‚îÄ histogram.c                    # Parallel histogram with synchronization
‚îÇ   ‚îî‚îÄ‚îÄ README.md                       # Task documentation
‚îÇ
‚îú‚îÄ‚îÄ Task4-Matrix-Transpose/
‚îÇ   ‚îú‚îÄ‚îÄ matrix_transpose.c             # Block partition transpose
‚îÇ   ‚îî‚îÄ‚îÄ README.md                       # Task documentation
‚îÇ
‚îú‚îÄ‚îÄ Task5-Vector-Addition/
‚îÇ   ‚îú‚îÄ‚îÄ vector_addition.c              # Element partitioning
‚îÇ   ‚îî‚îÄ‚îÄ README.md                       # Task documentation
‚îÇ
‚îú‚îÄ‚îÄ Task6-Sparse-Matrix/
‚îÇ   ‚îú‚îÄ‚îÄ sparse_matrix_vector.c         # CSR format multiplication
‚îÇ   ‚îî‚îÄ‚îÄ README.md                       # Task documentation
‚îÇ
‚îú‚îÄ‚îÄ Makefile                            # Build configuration
‚îú‚îÄ‚îÄ README.md                           # This file
‚îú‚îÄ‚îÄ PERFORMANCE_FIXES.md                # ‚≠ê Detailed explanation of all performance fixes
‚îî‚îÄ‚îÄ QUICK_REFERENCE.md                  # ‚≠ê Quick guide for common patterns & anti-patterns
```

---

## ‚ö†Ô∏è IMPORTANT: Performance Fixes Applied

**All tasks have been optimized to achieve positive speedup!**

- üìñ **Read [PERFORMANCE_FIXES.md](PERFORMANCE_FIXES.md)** for detailed explanation of all critical bugs and their fixes
- üéØ **Read [QUICK_REFERENCE.md](QUICK_REFERENCE.md)** for best practices and common anti-patterns to avoid

**Key fixes:**
- ‚úÖ Task 1: Removed atomic operations from hot loop (was 31x slower, now 8-12x faster)
- ‚úÖ Task 3: Implemented proper reduction pattern (was 500x slower, now 5-10x faster)
- ‚úÖ Task 4: Verified no synchronization issues, added memory-bound documentation
- ‚úÖ Task 5: Added comprehensive documentation about memory bandwidth limits
- ‚úÖ Task 6: Verified correctness, added performance scaling guidance

---

## üöÄ Quick Start

### Prerequisites

- **Compiler:** GCC with OpenMP support
- **OS:** Windows (MinGW/MSYS2), Linux, or macOS
- **OpenMP Version:** 3.0 or higher

### Compilation

**Compile all tasks:**

```bash
make all
```

**Compile individual tasks:**

```bash
# Task 1 - Matrix Multiplication
gcc -fopenmp -o Task1-Matrix-Multiplication/matrix_multiplication.exe Task1-Matrix-Multiplication/matrix_multiplication.c -lm

# Task 2 - File Encryption
gcc -fopenmp -o Task2-File-Encryption/file_encryption.exe Task2-File-Encryption/file_encryption.c

# Task 3 - Histogram
gcc -fopenmp -o Task3-Histogram/histogram.exe Task3-Histogram/histogram.c

# Task 4 - Matrix Transpose
gcc -fopenmp -o Task4-Matrix-Transpose/matrix_transpose.exe Task4-Matrix-Transpose/matrix_transpose.c

# Task 5 - Vector Addition
gcc -fopenmp -o Task5-Vector-Addition/vector_addition.exe Task5-Vector-Addition/vector_addition.c

# Task 6 - Sparse Matrix-Vector Multiplication
gcc -fopenmp -o Task6-Sparse-Matrix/sparse_matrix_vector.exe Task6-Sparse-Matrix/sparse_matrix_vector.c
```

### Running the Programs

```bash
# Task 1 - Matrix Multiplication
.\Task1-Matrix-Multiplication\matrix_multiplication.exe

# Task 2 - File Encryption
.\Task2-File-Encryption\file_encryption.exe input.bin output.bin

# Task 3 - Histogram
.\Task3-Histogram\histogram.exe

# Task 4 - Matrix Transpose
.\Task4-Matrix-Transpose\matrix_transpose.exe

# Task 5 - Vector Addition
.\Task5-Vector-Addition\vector_addition.exe

# Task 6 - Sparse Matrix-Vector Multiplication
.\Task6-Sparse-Matrix\sparse_matrix_vector.exe
```

---

## üìù Task Details

### Task 1: Large Matrix Multiplication (Block Decomposition)

**Description:** Implements parallel matrix multiplication by dividing large matrices into sub-blocks. Each thread multiplies a block pair and stores partial results in a shared output matrix.

**Key Features:**

- Block-based data decomposition
- Shared output matrix with synchronization
- Uses reduction or critical sections to accumulate results
- Performance comparison with sequential multiplication
- Configurable block size for optimization

**OpenMP Concepts:**

- Parallel for loops with collapse
- Critical sections for result accumulation
- Reduction operations
- Shared and private data management

**Complexity:** O(n¬≥) with parallelization speedup

---

### Task 2: Parallel File Encryption

**Description:** Splits a large binary file into chunks and encrypts each chunk in parallel using XOR or AES-style encryption. Output writes are synchronized to preserve order.

**Key Features:**

- Chunk-based file decomposition
- Parallel XOR encryption (with optional AES logic)
- Thread-safe file I/O
- Order-preserving output synchronization
- Support for large binary files

**OpenMP Concepts:**

- Static scheduling for chunk assignment
- Critical sections for ordered writes
- File handling in parallel context
- Memory-efficient chunk processing

**Encryption Methods:**

- XOR cipher (simple, fast)
- Pseudo-AES logic (demonstration)

---

### Task 3: Parallel Histogram Computation

**Description:** Given a large array of integers (0-9), decomposes the data among threads to build a shared histogram with proper synchronization.

**Key Features:**

- Data partitioning among threads
- Shared histogram array
- Atomic operations for thread-safe updates
- Local histogram reduction strategy
- Performance measurement

**OpenMP Concepts:**

- Parallel for with reduction
- Atomic operations
- Private local histograms
- Reduction on array variables

**Algorithm:** Each thread computes a local histogram, then combines results.

---

### Task 4: Matrix Transpose (Block Data Partition)

**Description:** Divides the input matrix into smaller sub-blocks and assigns each block transpose operation to a separate thread.

**Key Features:**

- Block-based decomposition
- Cache-efficient memory access patterns
- Parallel block transposition
- In-place vs. out-of-place options
- Performance analysis

**OpenMP Concepts:**

- Nested parallel loops
- 2D domain decomposition
- Memory layout optimization
- Load balancing

**Benefits:** Improved cache utilization with blocked access patterns.

---

### Task 5: Vector Addition (Element Partitioning)

**Description:** Implements parallel addition of two large vectors by partitioning elements evenly among threads using OpenMP.

**Key Features:**

- Simple element-wise decomposition
- Perfect load balancing
- Minimal synchronization overhead
- Performance scaling analysis
- Comparison with sequential version

**OpenMP Concepts:**

- Basic parallel for loops
- Static scheduling
- First-touch memory placement
- Speedup measurement

**Complexity:** O(n) with near-linear speedup expected.

---

### Task 6: Parallel Sparse Matrix-Vector Multiplication

**Description:** Represents sparse matrices in CSR (Compressed Sparse Row) format and assigns row blocks to threads. Handles irregular workload balancing.

**Key Features:**

- CSR format representation
- Row-based decomposition
- Dynamic scheduling for load balancing
- Handles irregular sparse patterns
- Efficient memory usage

**OpenMP Concepts:**

- Dynamic scheduling
- Irregular workload handling
- Sparse data structures
- Performance profiling

**CSR Format:** (values[], col_indices[], row_ptr[])

---

## üéØ Data Decomposition Strategies

This assignment demonstrates various data decomposition patterns:

### 1. Block Decomposition (Tasks 1, 4)

Divides matrices into rectangular blocks for better cache locality.

```c
#pragma omp parallel for collapse(2)
for (int bi = 0; bi < N; bi += BLOCK_SIZE)
    for (int bj = 0; bj < N; bj += BLOCK_SIZE)
        // Process block
```

### 2. Chunk-Based Decomposition (Task 2)

Divides file/data into equal-sized chunks.

```c
#pragma omp parallel for schedule(static)
for (int chunk = 0; chunk < num_chunks; chunk++)
    // Process chunk
```

### 3. Element Partitioning (Task 5)

Direct element-wise distribution.

```c
#pragma omp parallel for
for (int i = 0; i < N; i++)
    C[i] = A[i] + B[i];
```

### 4. Row-Based Decomposition (Task 6)

Assigns rows to threads (useful for sparse matrices).

```c
#pragma omp parallel for schedule(dynamic)
for (int row = 0; row < num_rows; row++)
    // Process row
```

---

## üîß Synchronization Techniques

### Atomic Operations (Task 3)

```c
#pragma omp atomic
histogram[value]++;
```

### Critical Sections (Tasks 1, 2)

```c
#pragma omp critical
{
    // Thread-safe code
}
```

### Reduction (Task 3)

```c
#pragma omp parallel for reduction(+:sum)
for (int i = 0; i < N; i++)
    sum += array[i];
```

---

## üìä Expected Performance Results

### Task 1: Matrix Multiplication (1024√ó1024)

- **Sequential Time:** ~2.5 seconds
- **Parallel Time (8 threads):** ~0.4 seconds
- **Speedup:** ~6.2x

### Task 2: File Encryption (100 MB file)

- **Sequential Time:** ~1.2 seconds
- **Parallel Time (8 threads):** ~0.2 seconds
- **Speedup:** ~6.0x

### Task 3: Histogram (10 million elements)

- **Sequential Time:** ~0.05 seconds
- **Parallel Time (8 threads):** ~0.008 seconds
- **Speedup:** ~6.2x

### Task 5: Vector Addition (100 million elements)

- **Sequential Time:** ~0.3 seconds
- **Parallel Time (8 threads):** ~0.04 seconds
- **Speedup:** ~7.5x

### Task 6: Sparse Matrix-Vector (10K rows, 1% density)

- **Sequential Time:** ~0.02 seconds
- **Parallel Time (8 threads):** ~0.004 seconds
- **Speedup:** ~5.0x

*Note: Results vary based on hardware and problem size.*

---

## üéì Learning Objectives

This assignment teaches:

‚úÖ **Data Decomposition Patterns**

- Block decomposition
- Chunk-based partitioning
- Element-wise distribution
- Irregular decomposition

‚úÖ **Synchronization Mechanisms**

- Atomic operations
- Critical sections
- Reduction operations
- Ordered execution

‚úÖ **Performance Optimization**

- Cache efficiency
- Load balancing
- Minimizing synchronization overhead
- Scalability analysis

‚úÖ **Real-World Applications**

- Matrix operations (linear algebra)
- Data encryption (security)
- Data analysis (histograms)
- Sparse computations (scientific computing)

---

## ‚ö†Ô∏è Performance Considerations

### Problem Size Matters

Parallel programs have overhead (thread creation, synchronization, scheduling). For positive speedup:

- **Task 1 (Matrix Multiply):** Use N ‚â• 512 (default 512 is good)
- **Task 2 (File Encryption):** Use files ‚â• 10 MB
- **Task 3 (Histogram):** Use ‚â• 10M elements (default is good)
- **Task 4 (Transpose):** Use N ‚â• 4096 (default increased to 4096)
- **Task 5 (Vector Add):** Use ‚â• 100M elements (memory-bound)
- **Task 6 (Sparse Matrix):** Use ‚â• 50K rows (default increased to 50K)

### Memory-Bound vs Compute-Bound

- **Compute-bound** (Tasks 1, 3, 4, 6): Speedup scales with threads
- **Memory-bound** (Tasks 2, 5): Speedup limited by bandwidth

### Common Pitfalls FIXED

‚úÖ **NO atomic operations in hot loops** - All tasks restructured to avoid this
‚úÖ **Each thread owns its data** - No shared writes during computation  
‚úÖ **Proper work partitioning** - Complete blocks/rows assigned to threads
‚úÖ **Minimal synchronization** - Only at boundaries, not in inner loops

## üêõ Troubleshooting

**Problem: Compilation errors with OpenMP**

- Ensure `-fopenmp` flag is included
- Check GCC version (>= 4.2 recommended)

**Problem: Poor speedup with small inputs**

- **This is normal!** Parallel overhead > computation for small problems
- Increase problem size (see "Problem Size Matters" above)
- With proper input sizes, expect 4-12x speedup

**Problem: Memory-bound tasks (2, 5) show lower speedup**

- Expected! Limited by memory bandwidth, not CPU
- Speedup saturates at memory bandwidth limit (typically 4-8x)

**Problem: Incorrect results**

- Check for race conditions
- Verify synchronization
- Test with sequential version first

---

## üìö Additional Resources

- [OpenMP Data Environment](https://www.openmp.org/spec-html/5.0/openmpse14.html)
- [Parallel Patterns Guide](https://patterns.eecs.berkeley.edu/)
- [Matrix Multiplication Optimization](https://en.wikipedia.org/wiki/Matrix_multiplication_algorithm)
- [CSR Format Explanation](https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_(CSR,_CRS_or_Yale_format))

---

## üë§ Author Information

**Course Code:** CCS4210  
**Course Name:** High Performance Computing  
**Assignment:** Sheet #03 - Data Decomposition  
**Instructor:** Dr. Hanan Hassan  
**TA:** Marwa Alazab  
**Semester:** Term 7 (2025)

---

## üìÑ License

This project is for educational purposes as part of the HPC course assignment.

---

## üîç Key Takeaways

1. **Choose the right decomposition:** Block decomposition for matrices, chunk-based for files, element-wise for vectors
2. **Balance workload:** Use dynamic scheduling for irregular workloads
3. **Minimize synchronization:** Use local computations then combine results
4. **Cache awareness:** Block decomposition improves cache utilization
5. **Measure performance:** Always compare with sequential baseline

---

**Note:** Each task folder contains detailed documentation, implementation notes, and usage examples. Refer to individual README files for specific details.

#   o p e n m p - d a t a - p a t t e r n s  
 